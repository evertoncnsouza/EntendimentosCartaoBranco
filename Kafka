O Kafka combina três recursos principais para que você possa implementar seus casos de
uso para streaming de eventos de ponta a ponta com uma única solução testada em batalha:

- Para publicar (gravar) e assinar (ler) fluxos de eventos, incluindo importação /
exportação contínua de seus dados de outros sistemas.
- Para armazenar fluxos de eventos de forma durável e confiável pelo tempo que você
quiser.
- Para processar fluxos de eventos conforme eles ocorrem ou retrospectivamente.

E toda essa funcionalidade é fornecida de maneira distribuída, altamente escalável,
elástica, tolerante a falhas e segura. O Kafka pode ser implantado em hardware
bare-metal, máquinas virtuais e contêineres, e no local, bem como na nuvem. 
Você pode escolher entre o autogerenciamento de seus ambientes Kafka e o uso de
serviços totalmente gerenciados oferecidos por uma variedade de fornecedores.

##########################################################################
Como funciona!

Kafka é um sistema distribuído que consiste em servidores e clientes que se comunicam
por meio de um protocolo de rede TCP de alto desempenho . Ele pode ser implantado em 
hardware bare-metal, máquinas virtuais e contêineres no local, bem como em ambientes 
de nuvem.

Servidores : o Kafka é executado como um cluster de um ou mais servidores que podem 
abranger vários datacenters ou regiões de nuvem. Alguns desses servidores formam a 
camada de armazenamento, chamados de corretores. Outros servidores executam o Kafka
Connect para importar e exportar dados continuamente como fluxos de eventos para 
integrar o Kafka com seus sistemas existentes, como bancos de dados relacionais, 
bem como outros clusters Kafka. Para permitir que você implemente casos de uso de 
missão crítica, um cluster Kafka é altamente escalonável e tolerante a falhas: se 
algum de seus servidores falhar, os outros servidores assumirão seu trabalho para 
garantir operações contínuas sem nenhuma perda de dados.

Clientes : eles permitem que você escreva aplicativos e microsserviços distribuídos
que leem, gravam e processam fluxos de eventos em paralelo, em escala e de maneira
tolerante a falhas, mesmo no caso de problemas de rede ou falhas de máquina. 
O Kafka vem com alguns desses clientes incluídos, que são aumentados por dezenas de 
clientes fornecidos pela comunidade Kafka: os clientes estão disponíveis para Java e
Scala, incluindo a biblioteca Kafka Streams de nível superior , para Go, Python, C /
C ++ e muitas outras programações linguagens, bem como APIs REST.

Principais conceitos e terminologia
Um evento registra o fato de que "algo aconteceu" no mundo ou no seu negócio. 
Também é chamado de registro ou mensagem na documentação. Ao ler ou gravar dados no
Kafka, você o faz na forma de eventos. Conceitualmente, um evento possui uma chave,
um valor, um carimbo de data / hora e cabeçalhos de metadados opcionais. 
Aqui está um exemplo de evento:

Chave do evento: "Alice"
Valor do evento: "Efetuou um pagamento de $ 200 para Bob"
Data e hora do evento: "25 de junho de 2020 às 14h06"
Os produtores são os aplicativos clientes que publicam (gravam) eventos no Kafka e
os consumidores são os que assinam (lêem e processam) esses eventos.
Em Kafka, produtores e consumidores são totalmente dissociados e agnósticos entre si,
o que é um elemento chave de design para alcançar a alta escalabilidade pela qual 
Kafka é conhecida. Por exemplo, os produtores nunca precisam esperar pelos 
consumidores. O Kafka oferece várias garantias , como a capacidade de processar 
eventos exatamente uma vez.

Os eventos são organizados e armazenados de forma duradoura em tópicos . 
Muito simplificado, um tópico é semelhante a uma pasta em um sistema de arquivos,
e os eventos são os arquivos dessa pasta. Um exemplo de nome de tópico poderia ser
"pagamentos". Os tópicos no Kafka são sempre multiprodutor e multi-assinante: um 
tópico pode ter zero, um ou muitos produtores que gravam eventos nele, bem como zero,
um ou muitos consumidores que assinam esses eventos. Os eventos em um tópico podem 
ser lidos com a frequência necessária - ao contrário dos sistemas de mensagens
tradicionais, os eventos não são excluídos após o consumo. Em vez disso, você define
por quanto tempo o Kafka deve reter seus eventos por meio de uma definição de 
configuração por tópico, após o qual os eventos antigos serão descartados. 
O desempenho do Kafka é efetivamente constante com relação ao tamanho dos dados, 
portanto, armazenar dados por um longo tempo é perfeitamente adequado.

Os tópicos são particionados , o que significa que um tópico é espalhado por vário
s "depósitos" localizados em diferentes corretores Kafka. Esse posicionamento
distribuído de seus dados é muito importante para a escalabilidade, pois permite que
os aplicativos clientes leiam e gravem os dados de / para vários corretores ao mesmo
tempo. Quando um novo evento é publicado em um tópico, ele na verdade é anexado a uma
das partições do tópico. Eventos com a mesma chave de evento (por exemplo, 
um cliente ou ID de veículo) são gravados na mesma partição, e Kafka garante que
qualquer consumidor de uma determinada partição de tópico sempre lerá os eventos
dessa partição exatamente na mesma ordem em que foram gravados.

#########################################################

APIs Kafka
Além das ferramentas de linha de comando para tarefas de gerenciamento e 
administração, o Kafka tem cinco APIs principais para Java e Scala:

A API Admin para gerenciar e inspecionar tópicos, corretores e outros objetos Kafka.
A API do Produtor para publicar (gravar) um fluxo de eventos para um ou mais tópicos
do Kafka.
A API do consumidor para assinar (ler) um ou mais tópicos e processar o fluxo de
eventos produzidos para eles.
A API Kafka Streams para implementar aplicativos de processamento de fluxo e 
microsserviços. Ele fornece funções de nível superior para processar fluxos de
eventos, incluindo transformações, operações com estado como agregações e junções,
janelas, processamento com base no horário do evento e muito mais. A entrada é lida 
de um ou mais tópicos a fim de gerar saída para um ou mais tópicos, transformando 
efetivamente os fluxos de entrada em fluxos de saída.
A API do Kafka Connect para construir e executar conectores de importação / 
exportação de dados reutilizáveis que consomem (lêem) ou produzem (gravam) fluxos 
de eventos de e para sistemas e aplicativos externos, para que possam se integrar ao 
Kafka. Por exemplo, um conector para um banco de dados relacional como PostgreSQL 
pode capturar todas as alterações em um conjunto de tabelas. No entanto, na prática,
você normalmente não precisa implementar seus próprios conectores porque a comunidade
Kafka já fornece centenas de conectores prontos para uso.

###############################################################
O Apache Kafka optou pelo uso do pull model, pois, provê algumas vantagens bem 
interessantes, por exemplo:

Consumidores conseguem controlar a quantidade de eventos que buscam, reduzindo as 
operações na rede.
Consumidores conseguem controlar quais mensagens querem consumir, por exemplo,
todas da última semana, ano, mês.
Apache Kafka não precisa controlar os envios de eventos.

#############################################################

A Zup utiliza sistema baseado em Pull.

#############################################################
- Tópico
Na arquitetura do Apache Kafka existem vários componentes, como por exemplo, o Tópico
que tem a responsabilidade de representar um stream de evento, como por exemplo,
um tópico de transações!

Uma analogia para a gente entender o que é um Tópico é dizer que o mesmo é uma tabela
no banco de dados, onde contém todos os registros e a ordem de cadastro dos mesmos!

Portanto, caso um determinado consumidor queira consumir as transações, basta o mesmo
se conectar e começar operar no Tópico.

O Tópico no Apache Kafka tem uma característica bastante importante, a partição,
no qual permite ser distribuído em vários brokers do Kafka via Replication Factor.

###############################################################################
Partição 
Na arquitetura do Apache Kafka existem vários componentes, como por exemplo, o Tópico
que tem a responsabilidade de representar um stream de evento, como por exemplo, 
um tópico de transações!

O tópico é consistido por várias partições, de acordo com o configurado.

A partição é uma maneira de prover redundância e escalabilidade, pois, cada partição 
pode estar em um broker (máquina) diferente.

Além dos pontos citados acima temos a possibilidade de segmentar os eventos de acordo
com uma determinada chave!

Quando enviamos um evento sem chave, o tópico seleciona aleatoriamente a partição que
irá o evento, porém quando enviamos com uma chave, todos os eventos com a mesma chave
irá somente para aquela partição e de forma ordenada.

Dica: Aprenda sobre eventos ordenados, eventos não ordenados e recuperar eventos restrospectivamente.

#####################################################################################
Consumidor - 
Na arquitetura do Apache Kafka existem vários componentes, como por exemplo, o 
Consumidor que tem a responsabilidade de processar os eventos de um determinado 
tópico.

O consumidor se escreve em um ou mais partições de um determinado tópico e processa 
os eventos conforme eles vão sendo gerados!

A cada processamento o consumidor tem a responsabilidade de gravar em qual ponto ele
parou de ler e em qual partição.

Um ponto bastante interessante é que se houver a necessidade de processar novamente
os eventos, basta o consumidor zerar seu histórico de processamento (offset), pois,
o Apache Kafka armazena os eventos de cada partição de acordo com o configurado 
1 dia, mês, ano, etc.

Para que isso seja possível o consumidor precisa configurar qual modelo ele quer
fazer de coletar de eventos:

latest: Processa a partir do último processado.
earliest: Zera o offset e processa desde o início.
none: Não processa nenhum evento e lança uma exceção em sua aplicação.

Consumer group -  Tem a responsabilidade de prover grupos de consumidores e balancear
a carga de trabalho de acordo com a quantidade de partições!

Todo consumidor no Apache Kafka deve pertencer a um grupo, e o controle de histórico
de processamento é por grupo e partição.

O modelo de escalabilidade do consumidor está atrelado a quantidade de consumidor x 
partições.

Dica: Sempre que utilizar Kafka pense em idempotência nos consumidores, pois, pode ser
que um dia seja utilizada a funcionalidade de processar todos os eventos. Tenha cuidado
com o modelo de commit períodico(Auto commit). 
Se seu consumidor processou 10 eventos e por algum motivo caiu e não foi executado o 
commit periódico, ao subir novamente, seu consumidor irá processar novamente os 10
eventos.
################################################################################

Produtor - 
Tem a responsabilidade de enviar os eventos de um determinado tópico.

O produtor envia os eventos para o broker líder, ou seja, em um conjunto de máquinas 
(brokers) que formam o cluster Kafka, é eleito um líder que irá receber os eventos de
acordo com o tópico e partição! Portanto, no Apache Kafka não existe um líder geral e
sim um líder específico por partição.

Para que seja possível saber os líderes o Apache Kafka informa para os produtores
quais brokers estão aptos a receber eventos, por isso, é de extrema importância ter 
replicações das partições, pois, se uma máquina (broker) cai a outra assume a
liderança da(s) partição(ões)!

Para enviar um evento é preciso enviar as seguintes informações:
- Nome do tópico.
- Corpo do evento, geralmente enviado no formato JSON.
- Chave (Opcional), caso deseje que todas as mensagens sejam enviadas para uma mesma
 partição e de forma ordenada.

Ciclo de vida do Retry - (Pesquisar)

Além do ciclo de vida do Retry, é possível configurar o modelo de reconhecimento do 
envio do evento. Isto pode ser útil para garantir de fato que o evento foi replicado.

Para que seja possível, o produtor deve informar qual modelo de reconhecimento(acks) 
ele quer. 
Ex: : 
- O produtor não irá esperar pelo reconhecimento do recebimento do evento pelo 
Apache Kafka.
- 1: O produtor somente irá esperar pelo reconhecimento do recebimento do evento pelo
líder.
- all: O produtor irá esperar pelo reconhecimento do recebimento do evento por todos
os brokers que tenha a partição!

Portanto para não perder mensagens é melhor utilizar o modelo do tipo all.

Dica: Leve sempre em consideração os pontos
- Modelo de reconhecimento
- Quantidade de retry
- Idempotência



















